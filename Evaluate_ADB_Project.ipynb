{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj9-3U--Krvc"
      },
      "source": [
        "# This Notebook for Running the ADB Project Phase 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hV2Nc_f8Mbqh"
      },
      "source": [
        "**This notebook is divided into two main parts, each focusing on different database sizes:**\n",
        "- **Part 1: Database Size 10K**\n",
        "  - Initiate a new database and insert vectors into it.\n",
        "  - Retrieve vectors from the database.\n",
        "  - Ensure that the insertion time for this database does not exceed 5 minutes.\n",
        "  - Allow flexible RAM usage during insertion but ensure it stays within Google Colab limits.\n",
        "  - Evaluate retrieval time and accuracy.\n",
        "  - Ensure that the peak RAM usage for retrieval does not exceed 5 MB.\n",
        "\n",
        "- **Part 2: Database Sizes 100K and More**\n",
        "  - Generate database vectors using a random seed (refer to the provided code).\n",
        "  - You have generate the database and its index before the submission.\n",
        "  - Implement a VecDB class that loads the pre-generated database, including the index, and retrieves vectors, to load the generated database.\n",
        "  - Evaluate retrieval time and accuracy for different database sizes.\n",
        "  - The Peak RAM usage for the retrieval should not exceed\n",
        "    - For 100 K --> 10 MB\n",
        "    - For 1 M --> 25 MB\n",
        "    - For 5 M --> 75 MB\n",
        "    - For 10 M --> 150 MB\n",
        "    - For 15 M --> 225 MB\n",
        "    - For 20 M --> 300 MB\n",
        "\n",
        "**This notebook is structured into two parts:**\n",
        "\n",
        "- **Part 1 - Modifiable Cells:**\n",
        "This section contains cells that teams are allowed to modify. The modification are only variables and to be submitted during the project's final phase. They are\n",
        "  - GitHub repository link (including PAT token).\n",
        "  - Database (DB) variables, providing the path to the directory or file for loading existing databases and indexes (refer to provided code to see how).\n",
        "\n",
        "- **Part 2 - Non-Modifiable Cells:** This section must not be modified by any team. It includes essential setup and evaluation code. Ensure that the notebook runs smoothly by providing the required inputs in Part 1.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4EV_xB6Kw17"
      },
      "source": [
        "## Part 1 - Modifiable Cells"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AODP-iztLtBV"
      },
      "source": [
        "Of course each team will provide different github repo link\n",
        "Should include PAT token to enable me to download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCR6Z8ABxE3w",
        "outputId": "62629764-e4fa-4159-ea30-69c71d7bdedf"
      },
      "outputs": [],
      "source": [
        "#!git clone https://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:@github.com/abdokaseb/sematic_search_DB.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsUXWYom6xRv"
      },
      "source": [
        "Teams are required to provide unique paths for the generated databases of sizes 1M, 5M, 10M, 15M, and 20M. Follow these steps to submit the databases:\n",
        "\n",
        "- Once you have the database and index ready, zip the necessary folders/files.\n",
        "- Upload the zip file to Google Drive.\n",
        "- Ensure the file is shareable with \"anyone with the link.\"\n",
        "- Obtain the zip file link (e.g., https://drive.google.com/file/d/1j1gAU3kvdRqcOoKI5K5FgMMUZpOQANah/view?usp=drive_link).\n",
        "- Extract the zip file ID (e.g., 1j1gAU3kvdRqcOoKI5K5FgMMUZpOQANah).\n",
        "- Place the ID in the designated variable (to be submitted during the project final phase).\n",
        "- The code will automatically download the zip file and unzip it inside this directory.\n",
        "- Provide the local PATH for each database to be passed to the initializer for automatic loading of the database and index (to be submitted during the project final phase)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kK46_ZVe5L3u"
      },
      "outputs": [],
      "source": [
        "# TEAM_NUMBER = 1\n",
        "# GDRIVE_ID_DB_100K = \"14Gp_C3LxLuYIyF-zL5q-xFXKQ8KOFtZp\"\n",
        "# GDRIVE_ID_DB_1M = \"1XbEP6sU0k0UbuPcQLkHJP7cdPtebpsbD\"\n",
        "# GDRIVE_ID_DB_5M = \"1DX0tw9YDlvRthjMq3LQ6_aUyp3BvTC1r\"\n",
        "# GDRIVE_ID_DB_10M = \"1Jho9rair77eWdA5-iI_qDT2spJNesuDe\"\n",
        "# GDRIVE_ID_DB_15M = \"1sPIgNxIuNDUUBnTvAuPMLryd1mqmgwV3\"\n",
        "# GDRIVE_ID_DB_20M = \"1j1gAU3kvdRqcOoKI5K5FgMMUZpOQANah\"\n",
        "PATH_DB_100K = \"saved_db_100k.csv\"\n",
        "PATH_DB_1M = \"saved_db_1m.csv\"\n",
        "PATH_DB_5M = \"saved_db_5m.csv\"\n",
        "PATH_DB_10M = \"saved_db_10m.csv\"\n",
        "PATH_DB_15M = \"saved_db_15m.csv\"\n",
        "PATH_DB_20M = \"saved_db_20m.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LGLg01fsujm"
      },
      "source": [
        "These two varaible I'll change while running in on the discussion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "G44iH6jnObEj"
      },
      "outputs": [],
      "source": [
        "QUERY_SEED_NUMBER = 10\n",
        "DB_SEED_NUMBER = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWaZ-ByWOIcK"
      },
      "source": [
        "This means that the project submission will include these\n",
        "- TEAM_NUMBER\n",
        "- Github clone link\n",
        "- GDRIVE_ID_DB_100K\n",
        "- GDRIVE_ID_DB_1M\n",
        "- GDRIVE_ID_DB_5M\n",
        "- GDRIVE_ID_DB_10M\n",
        "- GDRIVE_ID_DB_15M\n",
        "- GDRIVE_ID_DB_20M\n",
        "- PATH_DB_100K\n",
        "- PATH_DB_1M\n",
        "- PATH_DB_5M\n",
        "- PATH_DB_10M\n",
        "- PATH_DB_15M\n",
        "- PATH_DB_20M <br>\n",
        "- And for sure the project document that describes what you did"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzFTOecwu8wj"
      },
      "source": [
        "## Part 2: No edits from here\n",
        "#### You can't edit this part, and neither me.\n",
        "#### Note: Maybe I can edit if there is a major bug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dqujj7tYTA1l",
        "outputId": "0e2c6175-c752-4aa1-b3eb-63027df98871"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WinError 2] The system cannot find the file specified: 'sematic_search_DB'\n",
            "c:\\Users\\Seif\\Documents\\GitHub\\Adb\n"
          ]
        }
      ],
      "source": [
        "%cd sematic_search_DB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJmXzFdisD7P"
      },
      "source": [
        "This cell to run any additional requirement that your code need <br>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaPjq2hMqd20",
        "outputId": "b6bcd988-7458-434f-d256-4486e4da807a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.1.2 -> 23.3.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install memory-profiler >> log.txt\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lG0DALR498__"
      },
      "source": [
        "This cell to download the zip files and unzip them here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSv2z0PVp6HA",
        "outputId": "f9cf0dbd-2c18-4042-8471-dab82ff0cb93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=14Gp_C3LxLuYIyF-zL5q-xFXKQ8KOFtZp\n",
            "To: /content/sematic_search_DB/saved_db_100k.zip\n",
            "100% 28.5M/28.5M [00:00<00:00, 41.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1XbEP6sU0k0UbuPcQLkHJP7cdPtebpsbD\n",
            "To: /content/sematic_search_DB/saved_db_1m.zip\n",
            "100% 28.5M/28.5M [00:00<00:00, 37.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1DX0tw9YDlvRthjMq3LQ6_aUyp3BvTC1r\n",
            "To: /content/sematic_search_DB/saved_db_5m.zip\n",
            "100% 28.5M/28.5M [00:00<00:00, 91.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Jho9rair77eWdA5-iI_qDT2spJNesuDe\n",
            "To: /content/sematic_search_DB/saved_db_10m.zip\n",
            "100% 28.5M/28.5M [00:00<00:00, 34.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1sPIgNxIuNDUUBnTvAuPMLryd1mqmgwV3\n",
            "To: /content/sematic_search_DB/saved_db_15m.zip\n",
            "100% 28.5M/28.5M [00:00<00:00, 116MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1j1gAU3kvdRqcOoKI5K5FgMMUZpOQANah\n",
            "To: /content/sematic_search_DB/saved_db_20m.zip\n",
            "100% 28.5M/28.5M [00:00<00:00, 142MB/s]\n",
            "Archive:  saved_db_100k.zip\n",
            "  inflating: saved_db_100k.csv       \n",
            "Archive:  saved_db_1m.zip\n",
            "  inflating: saved_db_1m.csv         \n",
            "Archive:  saved_db_5m.zip\n",
            "  inflating: saved_db_5m.csv         \n",
            "Archive:  saved_db_10m.zip\n",
            "  inflating: saved_db_10m.csv        \n",
            "Archive:  saved_db_15m.zip\n",
            "  inflating: saved_db_15m.csv        \n",
            "Archive:  saved_db_20m.zip\n",
            "  inflating: saved_db_20m.csv        \n"
          ]
        }
      ],
      "source": [
        "!gdown $GDRIVE_ID_DB_100K -O saved_db_100k.zip\n",
        "!gdown $GDRIVE_ID_DB_1M -O saved_db_1m.zip\n",
        "!gdown $GDRIVE_ID_DB_5M -O saved_db_5m.zip\n",
        "!gdown $GDRIVE_ID_DB_10M -O saved_db_10m.zip\n",
        "!gdown $GDRIVE_ID_DB_15M -O saved_db_15m.zip\n",
        "!gdown $GDRIVE_ID_DB_20M -O saved_db_20m.zip\n",
        "!unzip saved_db_100k.zip\n",
        "!unzip saved_db_1m.zip\n",
        "!unzip saved_db_5m.zip\n",
        "!unzip saved_db_10m.zip\n",
        "!unzip saved_db_15m.zip\n",
        "!unzip saved_db_20m.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShuPR-gGlX3f"
      },
      "source": [
        "These are the functions for running and reporting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Sg2vfYgeyavn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from ivf_norm import VecDB\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "from typing import List\n",
        "from memory_profiler import memory_usage\n",
        "import gc\n",
        "\n",
        "@dataclass\n",
        "class Result:\n",
        "    run_time: float\n",
        "    top_k: int\n",
        "    db_ids: List[int]\n",
        "    actual_ids: List[int]\n",
        "\n",
        "results = []\n",
        "to_print_arr = []\n",
        "\n",
        "def run_queries(db, query, top_k, actual_ids, num_runs):\n",
        "    global results\n",
        "    results = []\n",
        "    for _ in range(num_runs):\n",
        "        tic = time.time()\n",
        "        db_ids = db.retrive(query, top_k)\n",
        "        print(db_ids)\n",
        "        print(actual_ids)\n",
        "        toc = time.time()\n",
        "        run_time = toc - tic\n",
        "        results.append(Result(run_time, top_k, db_ids, actual_ids))\n",
        "    return results\n",
        "\n",
        "def memory_usage_run_queries(args):\n",
        "    global results\n",
        "    # This part is added to calcauate the RAM usage\n",
        "    mem_before = max(memory_usage())\n",
        "    mem = memory_usage(proc=(run_queries, args, {}), interval = 1e-3)\n",
        "    return results, max(mem) - mem_before\n",
        "\n",
        "def evaluate_result(results: List[Result]):\n",
        "    # scores are negative. So getting 0 is the best score.\n",
        "    scores = []\n",
        "    run_time = []\n",
        "    for res in results:\n",
        "        run_time.append(res.run_time)\n",
        "        # case for retireving number not equal to top_k, socre will be the lowest\n",
        "        if len(set(res.db_ids)) != res.top_k or len(res.db_ids) != res.top_k:\n",
        "        #if len(set(tuple(row.flatten()) for row in res.db_ids)) != res.top_k or len(res.db_ids) != res.top_k:\n",
        "            scores.append( -1 * len(res.actual_ids) * res.top_k)\n",
        "            continue\n",
        "        score = 0\n",
        "        for id in res.db_ids:\n",
        "            try:\n",
        "                ind = res.actual_ids.index(id)\n",
        "                if ind > res.top_k * 3:\n",
        "                    score -= ind\n",
        "            except:\n",
        "                score -= len(res.actual_ids)\n",
        "        scores.append(score)\n",
        "\n",
        "    return sum(scores) / len(scores), sum(run_time) / len(run_time)\n",
        "\n",
        "def get_actual_ids_first_k(actual_sorted_ids, k):\n",
        "    return [id for id in actual_sorted_ids if id < k]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3bQQzzWlce4"
      },
      "source": [
        "This to generate 10K database and the query using the seed numbers that will be changed at submissions day"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "82Mb008w5YB7"
      },
      "outputs": [],
      "source": [
        "rng = np.random.default_rng(DB_SEED_NUMBER)\n",
        "vectors = rng.random((10**4, 70), dtype=np.float32)\n",
        "\n",
        "rng = np.random.default_rng(QUERY_SEED_NUMBER)\n",
        "query = rng.random((1, 70), dtype=np.float32)\n",
        "\n",
        "actual_sorted_ids_10k = np.argsort(vectors.dot(query.T).T / (np.linalg.norm(vectors, axis=1) * np.linalg.norm(query)), axis= 1).squeeze().tolist()[::-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiofTQ56l1wz"
      },
      "source": [
        "Open new DB add 10K then retrieve and evaluate. Then add another 90K (total 100K) then retrieve and evaluate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "broiY85IyDZ6",
        "outputId": "d9739d33-afdb-4bde-fecc-bf103cd945c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.7765375  0.9560017  0.2640193  0.20768178 0.79258186 0.82844484\n",
            "  0.51472414 0.1492821  0.8328704  0.51280457 0.15334606 0.13591957\n",
            "  0.41092372 0.6890364  0.4036622  0.8417477  0.00812364 0.42550898\n",
            "  0.52419096 0.956926   0.23533827 0.8253329  0.07183987 0.3382153\n",
            "  0.74872607 0.57576054 0.93872505 0.75330186 0.9143402  0.8271039\n",
            "  0.1357916  0.9334384  0.8445934  0.14499468 0.9784896  0.7455802\n",
            "  0.31431204 0.13935137 0.3885808  0.9065287  0.78565687 0.22611439\n",
            "  0.49179822 0.8532397  0.64099747 0.3063178  0.11379027 0.96983033\n",
            "  0.2343331  0.5178342  0.6922639  0.32247454 0.5165536  0.2824335\n",
            "  0.8366852  0.60586494 0.17676568 0.33376443 0.68798494 0.67864877\n",
            "  0.31203574 0.15442502 0.14845031 0.24977547 0.7895685  0.8698942\n",
            "  0.3430732  0.6003678  0.49958014 0.26198304]]\n",
            "10000\n",
            "Created batch file ./saved_db/batch0.npy containing 10000 vectors\n",
            "1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\conda\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1930: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10K\tscore\t-50000.0\ttime\t0.13\tRAM\t0.24 MB\n",
            "<ivf_norm.VecDB object at 0x000001D6281B0910>\n"
          ]
        }
      ],
      "source": [
        "db = VecDB()\n",
        "print(query)\n",
        "records_dict = [{\"id\": i, \"embed\": list(row)} for i, row in enumerate(vectors)]\n",
        "print(len(vectors))\n",
        "db.insert_records(records_dict) \n",
        "res = run_queries(db, query, 5, actual_sorted_ids_10k, 1) # one run to make everything fresh and loaded\n",
        "res, mem = memory_usage_run_queries((db, query, 5, actual_sorted_ids_10k, 5)) # actual runs to compute time, and memory\n",
        "eval = evaluate_result(res)\n",
        "to_print = f\"10K\\tscore\\t{eval[0]}\\ttime\\t{eval[1]:.2f}\\tRAM\\t{mem:.2f} MB\"\n",
        "to_print_arr.append(to_print)\n",
        "print(to_print)\n",
        "\n",
        "print(db)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZy7uYKeFQ-K"
      },
      "source": [
        "Remove exsiting varaibles to empty some RAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MreLqUWLn2uX",
        "outputId": "5c75eefc-24c5-4a43-ab75-ef7e7fd03ae0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "del vectors\n",
        "del query\n",
        "del actual_sorted_ids_10k\n",
        "del records_dict\n",
        "del db\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrOlipAOmy9K"
      },
      "source": [
        "This code to generate 20M database. The seed (50) will not be changed. Create the same DB and prepare it's files indexes and every related file. <br>\n",
        "Note at the submission I'll not run the insert records. <br>\n",
        "The query istelf will be changed at submissions day but not the DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "c83ybYSKK85G"
      },
      "outputs": [],
      "source": [
        "rng = np.random.default_rng(50)\n",
        "vectors = rng.random((10**7*2, 70), dtype=np.float32)\n",
        "\n",
        "rng = np.random.default_rng(QUERY_SEED_NUMBER)\n",
        "query = rng.random((1, 70), dtype=np.float32)\n",
        "query_dummy = rng.random((1, 70), dtype=np.float32)\n",
        "\n",
        "actual_sorted_ids_20m = np.argsort(vectors.dot(query.T).T / (np.linalg.norm(vectors, axis=1) * np.linalg.norm(query)), axis= 1).squeeze().tolist()[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzkAn4AF19Jl",
        "outputId": "33449337-8258-4b10-bb9c-5aa40331a35d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Team Number 5\n",
            "\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'PATH_DB_100K' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTeam Number\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(to_print_arr))\n\u001b[1;32m----> 4\u001b[0m db \u001b[38;5;241m=\u001b[39m VecDB(file_path \u001b[38;5;241m=\u001b[39m \u001b[43mPATH_DB_100K\u001b[49m, new_db \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m actual_ids \u001b[38;5;241m=\u001b[39m get_actual_ids_first_k(actual_sorted_ids_20m, \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m      6\u001b[0m res \u001b[38;5;241m=\u001b[39m run_queries(db, query_dummy, \u001b[38;5;241m5\u001b[39m, actual_ids, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# one run to make everything fresh and loaded\u001b[39;00m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'PATH_DB_100K' is not defined"
          ]
        }
      ],
      "source": [
        "print(\"Team Number\", \"5\")\n",
        "print(\"\\n\".join(to_print_arr))\n",
        "\n",
        "db = VecDB(file_path = PATH_DB_100K, new_db = False)\n",
        "actual_ids = get_actual_ids_first_k(actual_sorted_ids_20m, 10**5)\n",
        "res = run_queries(db, query_dummy, 5, actual_ids, 1)  # one run to make everything fresh and loaded\n",
        "res, mem = memory_usage_run_queries((db, query, 5, actual_ids, 3)) # actual runs to compute time, and memory\n",
        "eval = evaluate_result(res)\n",
        "to_print = f\"100K\\tscore\\t{eval[0]}\\ttime\\t{eval[1]:.2f}\\tRAM\\t{mem:.2f} MB\"\n",
        "to_print_arr.append(to_print)\n",
        "print(to_print)\n",
        "\n",
        "del db\n",
        "del actual_ids\n",
        "del res\n",
        "del mem\n",
        "del eval\n",
        "gc.collect()\n",
        "\n",
        "db = VecDB(file_path = PATH_DB_1M, new_db = False)\n",
        "actual_ids = get_actual_ids_first_k(actual_sorted_ids_20m, 10**6)\n",
        "res = run_queries(db, query_dummy, 5, actual_ids, 1)  # one run to make everything fresh and loaded\n",
        "res, mem = memory_usage_run_queries((db, query, 5, actual_ids, 3)) # actual runs to compute time, and memory\n",
        "eval = evaluate_result(res)\n",
        "to_print = f\"1M\\tscore\\t{eval[0]}\\ttime\\t{eval[1]:.2f}\\tRAM\\t{mem:.2f} MB\"\n",
        "to_print_arr.append(to_print)\n",
        "print(to_print)\n",
        "\n",
        "del db\n",
        "del actual_ids\n",
        "del res\n",
        "del mem\n",
        "del eval\n",
        "gc.collect()\n",
        "\n",
        "db = VecDB(file_path = PATH_DB_5M, new_db = False)\n",
        "actual_ids = get_actual_ids_first_k(actual_sorted_ids_20m, 10**6*5)\n",
        "res = run_queries(db, query_dummy, 5, actual_ids, 1)  # one run to make everything fresh and loaded\n",
        "res, mem = memory_usage_run_queries((db, query, 5, actual_ids, 3)) # actual runs to compute time, and memory\n",
        "eval = evaluate_result(res)\n",
        "to_print = f\"5M\\tscore\\t{eval[0]}\\ttime\\t{eval[1]:.2f}\\tRAM\\t{mem:.2f} MB\"\n",
        "to_print_arr.append(to_print)\n",
        "print(to_print)\n",
        "\n",
        "\n",
        "db = VecDB(file_path = PATH_DB_10M, new_db = False)\n",
        "actual_ids = get_actual_ids_first_k(actual_sorted_ids_20m, 10**6*10)\n",
        "res = run_queries(db, query_dummy, 5, actual_ids, 1)  # one run to make everything fresh and loaded\n",
        "res, mem = memory_usage_run_queries((db, query, 5, actual_ids, 3)) # actual runs to compute time, and memory\n",
        "eval = evaluate_result(res)\n",
        "to_print = f\"10M\\tscore\\t{eval[0]}\\ttime\\t{eval[1]:.2f}\\tRAM\\t{mem:.2f} MB\"\n",
        "to_print_arr.append(to_print)\n",
        "print(to_print)\n",
        "\n",
        "del db\n",
        "del actual_ids\n",
        "del res\n",
        "del mem\n",
        "del eval\n",
        "gc.collect()\n",
        "\n",
        "db = VecDB(file_path = PATH_DB_15M, new_db = False)\n",
        "actual_ids = get_actual_ids_first_k(actual_sorted_ids_20m, 10**6*15)\n",
        "res = run_queries(db, query_dummy, 5, actual_ids, 1)  # one run to make everything fresh and loaded\n",
        "res, mem = memory_usage_run_queries((db, query, 5, actual_ids, 3)) # actual runs to compute time, and memory\n",
        "eval = evaluate_result(res)\n",
        "to_print = f\"15M\\tscore\\t{eval[0]}\\ttime\\t{eval[1]:.2f}\\tRAM\\t{mem:.2f} MB\"\n",
        "to_print_arr.append(to_print)\n",
        "print(to_print)\n",
        "\n",
        "del db\n",
        "del actual_ids\n",
        "del res\n",
        "del mem\n",
        "del eval\n",
        "gc.collect()\n",
        "\n",
        "db = VecDB(file_path = PATH_DB_20M, new_db = False)\n",
        "actual_ids = get_actual_ids_first_k(actual_sorted_ids_20m, 10**6*20)\n",
        "res = run_queries(db, query_dummy, 5, actual_ids, 1)  # one run to make everything fresh and loaded\n",
        "res, mem = memory_usage_run_queries((db, query, 5, actual_ids, 3)) # actual runs to compute time, and memory\n",
        "eval = evaluate_result(res)\n",
        "to_print = f\"20M\\tscore\\t{eval[0]}\\ttime\\t{eval[1]:.2f}\\tRAM\\t{mem:.2f} MB\"\n",
        "to_print_arr.append(to_print)\n",
        "print(to_print)\n",
        "\n",
        "del db\n",
        "del actual_ids\n",
        "del res\n",
        "del mem\n",
        "del eval\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jt1_7ihfB37Z",
        "outputId": "6b5c944f-28d5-4d9e-93b4-bfff6904f676"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Team Number 1\n",
            "10K\tscore\t0.0\ttime\t1.50\tRAM\t0.61 MB\n",
            "100K\tscore\t-307208.0\ttime\t7.61\tRAM\t2.61 MB\n",
            "1M\tscore\t-3062013.0\ttime\t8.51\tRAM\t0.05 MB\n",
            "5M\tscore\t-15309954.0\ttime\t7.99\tRAM\t0.00 MB\n",
            "10M\tscore\t-30614896.0\ttime\t7.66\tRAM\t0.01 MB\n",
            "15M\tscore\t-45922276.0\ttime\t7.43\tRAM\t0.00 MB\n",
            "20M\tscore\t-61232472.0\ttime\t7.20\tRAM\t0.00 MB\n"
          ]
        }
      ],
      "source": [
        "print(\"Team Number\", TEAM_NUMBER)\n",
        "print(\"\\n\".join(to_print_arr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YneWf9F0oS2J"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a01AEyyiXp56"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
